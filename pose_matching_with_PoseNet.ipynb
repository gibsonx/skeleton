{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cVwtNDap-ZeZ",
        "0mrIuPeYthAA"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gibsonx/skeleton/blob/master/pose_matching_with_PoseNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6syB5sK0zUry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a813f945-e397-4618-837c-1a5f6e9ff2ae"
      },
      "source": [
        "# TODO:\n",
        "# 1. matching if not all keypoints (added flag to the kps (the third dim))\n",
        "!git clone https://github.com/Qengineering/TensorFlow_Lite_Pose_Jetson-Nano.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TensorFlow_Lite_Pose_Jetson-Nano'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 34 (delta 14), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (34/34), 12.78 MiB | 9.05 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeGSGnH8uTZQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tiw-xH4ihDy2"
      },
      "source": [
        "# Steps for running:\n",
        "# 1. Download PoseNet model from https://www.tensorflow.org/lite/models/pose_estimation/overview\n",
        "# 2. Choose your template and target image to process\n",
        "# 3. Specify paths"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWsKE24V8ayU"
      },
      "source": [
        "model_path = \"/content/TensorFlow_Lite_Pose_Jetson-Nano/posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\"\n",
        "template_path = \"person.jpg\"\n",
        "target_path = \"person_sit.jpeg\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKKi017Lujmd"
      },
      "source": [
        "# Load TFLite model and allocate tensors (memory usage method reducing latency)\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDmgx42v8AGr"
      },
      "source": [
        "# Get input and output tensors information from the model file\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "height = input_details[0]['shape'][1]\n",
        "width = input_details[0]['shape'][2]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_prEL6J8__I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "489a8e0d-33d0-430e-ecd3-3b91d58a98a5"
      },
      "source": [
        "template_image_src = cv.imread(template_path)\n",
        "# src_tepml_width, src_templ_height, _ = template_image_src.shape\n",
        "template_image = cv.resize(template_image_src, (width, height))\n",
        "cv2_imshow(template_image)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5182ee8de556>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemplate_image_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# src_tepml_width, src_templ_height, _ = template_image_src.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtemplate_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate_image_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyf-ougNRB-r"
      },
      "source": [
        "# can be used later to draw keypoints on the source image (before resizing)\n",
        "# templ_ratio_width = src_tepml_width/width\n",
        "# templ_ratio_height = src_templ_height/height"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOdfmzuRTk8b"
      },
      "source": [
        "target_image_src = cv.imread(target_path)\n",
        "# src_tar_width, src_tar_height, _ = target_image_src.shape\n",
        "target_image = cv.resize(target_image_src, (width, height))\n",
        "cv2_imshow(target_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgkhFXI4RnY3"
      },
      "source": [
        "# tar_ratio_width = src_tar_width/width\n",
        "# tar_ratio_height = src_tar_height/height"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYqpuz9W9gLc"
      },
      "source": [
        "# add a new dimension to match model's input\n",
        "template_input = np.expand_dims(template_image.copy(), axis=0)\n",
        "target_input = np.expand_dims(target_image.copy(), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1xGDbfD8GxV"
      },
      "source": [
        "# check the type of the input tensor\n",
        "floating_model = input_details[0]['dtype'] == np.float32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE1PZY4NBmG4"
      },
      "source": [
        "# Floating point models offer the best accuracy, at the expense of model size\n",
        "# and performance. GPU acceleration requires the use of floating point models.\n",
        "\n",
        "# Brings input values to range from 0 to 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoJG8LEA9g7R"
      },
      "source": [
        "if floating_model:\n",
        "  template_input = (np.float32(template_input) - 127.5) / 127.5\n",
        "  target_input = (np.float32(target_input) - 127.5) / 127.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP5Xm1dn9pOw"
      },
      "source": [
        "# Process template image\n",
        "# Sets the value of the input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], template_input)\n",
        "# Runs the computation\n",
        "interpreter.invoke()\n",
        "# Extract output data from the interpreter\n",
        "template_output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "template_offset_data = interpreter.get_tensor(output_details[1]['index'])\n",
        "# Getting rid of the extra dimension\n",
        "template_heatmaps = np.squeeze(template_output_data)\n",
        "template_offsets = np.squeeze(template_offset_data)\n",
        "print(\"template_heatmaps' shape:\", template_heatmaps.shape)\n",
        "print(\"template_offsets' shape:\", template_offsets.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2CnJ1CGcpi_"
      },
      "source": [
        "# Process target image. Same commands\n",
        "interpreter.set_tensor(input_details[0]['index'], target_input)\n",
        "interpreter.invoke()\n",
        "target_output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "target_offset_data = interpreter.get_tensor(output_details[1]['index'])\n",
        "target_heatmaps = np.squeeze(target_output_data)\n",
        "target_offsets = np.squeeze(target_offset_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWG76EIzAuUt"
      },
      "source": [
        "# The output consist of 2 parts:\n",
        "# - heatmaps (9,9,17) - corresponds to the probability of appearance of\n",
        "# each keypoint in the particular part of the image (9,9)(without applying sigmoid\n",
        "# function). Is used to locate the approximate position of the joint\n",
        "# - offset vectors (9,9,34) is called offset vectors. Is used for more exact\n",
        "#  calculation of the keypoint's position. First 17 of the third dimension correspond\n",
        "# to the x coordinates and the second 17 of them correspond to the y coordinates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPhePFS5aqF_"
      },
      "source": [
        "def parse_output(heatmap_data,offset_data, threshold):\n",
        "\n",
        "  '''\n",
        "  Input:\n",
        "    heatmap_data - hetmaps for an image. Three dimension array\n",
        "    offset_data - offset vectors for an image. Three dimension array\n",
        "    threshold - probability threshold for the keypoints. Scalar value\n",
        "  Output:\n",
        "    array with coordinates of the keypoints and flags for those that have\n",
        "    low probability\n",
        "  '''\n",
        "\n",
        "  joint_num = heatmap_data.shape[-1]\n",
        "  pose_kps = np.zeros((joint_num,3), np.uint32)\n",
        "\n",
        "  for i in range(heatmap_data.shape[-1]):\n",
        "\n",
        "      joint_heatmap = heatmap_data[...,i]\n",
        "      max_val_pos = np.squeeze(np.argwhere(joint_heatmap==np.max(joint_heatmap)))\n",
        "      remap_pos = np.array(max_val_pos/8*257,dtype=np.int32)\n",
        "      pose_kps[i,0] = int(remap_pos[0] + offset_data[max_val_pos[0],max_val_pos[1],i])\n",
        "      pose_kps[i,1] = int(remap_pos[1] + offset_data[max_val_pos[0],max_val_pos[1],i+joint_num])\n",
        "      max_prob = np.max(joint_heatmap)\n",
        "\n",
        "      if max_prob > threshold:\n",
        "        if pose_kps[i,0] < 257 and pose_kps[i,1] < 257:\n",
        "          pose_kps[i,2] = 1\n",
        "\n",
        "  return pose_kps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhecRA5Wasm7"
      },
      "source": [
        "def draw_kps(show_img,kps, ratio=None):\n",
        "    for i in range(5,kps.shape[0]):\n",
        "      if kps[i,2]:\n",
        "        if isinstance(ratio, tuple):\n",
        "          cv.circle(show_img,(int(round(kps[i,1]*ratio[1])),int(round(kps[i,0]*ratio[0]))),2,(0,255,255),round(int(1*ratio[1])))\n",
        "          continue\n",
        "        cv.circle(show_img,(kps[i,1],kps[i,0]),2,(0,255,255),-1)\n",
        "    return show_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAu-FoIjAk6W"
      },
      "source": [
        "template_show = np.squeeze((template_input.copy()*127.5+127.5)/255.0)\n",
        "template_show = np.array(template_show*255,np.uint8)\n",
        "template_kps = parse_output(template_heatmaps,template_offsets,0.3)\n",
        "cv2_imshow(draw_kps(template_show.copy(),template_kps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGsVUAnKApLS"
      },
      "source": [
        "target_show = np.squeeze((target_input.copy()*127.5+127.5)/255.0)\n",
        "target_show = np.array(target_show*255,np.uint8)\n",
        "target_kps = parse_output(target_heatmaps,target_offsets,0.3)\n",
        "cv2_imshow(draw_kps(target_show.copy(),target_kps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdUa-UZetJgp"
      },
      "source": [
        "### Matching by angles and proportions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn76NvQ6FEsM"
      },
      "source": [
        "#### Set template values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epsHJ98mGPFO"
      },
      "source": [
        "# Matching keypoints indices in the output of PoseNet\n",
        "# 0. Left shoulder to right shoulder (5-6)\n",
        "# 1. Left shoulder to left elbow (5-7)\n",
        "# 2. Right shoulder to right elbow (6-8)\n",
        "# 3. Left elbow to left wrist (7-9)\n",
        "# 4. Right elbow to right wrist (8-10)\n",
        "# 5. Left hip to right hip (11-12)\n",
        "# 6. Left shoulder to left hip (5-11)\n",
        "# 7. Right shoulder to right hip (6-12)\n",
        "# 8. Left hip to left knee (11-13)\n",
        "# 9. Right hip to right knee (12-14)\n",
        "# 10. Left knee to left ankle (13-15)\n",
        "# 11.  Right knee to right ankle (14-16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EShohUoHi6Ui"
      },
      "source": [
        "parts_to_compare = [(5,6),(5,7),(6,8),(7,9),(8,10),(11,12),(5,11),(6,12),(11,13),(12,14),(13,15),(14,16)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-1ZJvOmyfQw"
      },
      "source": [
        "def angle_length(p1, p2):\n",
        "\n",
        "  '''\n",
        "  Input:\n",
        "    p1 - coordinates of point 1. List\n",
        "    p2 - coordinates of point 2. List\n",
        "  Output:\n",
        "    Tuple containing the angle value between the line formed by two input points\n",
        "    and the x-axis as the first element and the length of this line as the second\n",
        "    element\n",
        "  '''\n",
        "\n",
        "  angle = math.atan2(- int(p2[0]) + int(p1[0]), int(p2[1]) - int(p1[1])) * 180.0 / np.pi\n",
        "  length = math.hypot(int(p2[1]) - int(p1[1]), - int(p2[0]) + int(p1[0]))\n",
        "\n",
        "  return round(angle), round(length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw7eTSyijTZc"
      },
      "source": [
        "template_values = []\n",
        "for part in parts_to_compare:\n",
        "  template_values.append(angle_length(template_kps[part[0]][:2], template_kps[part[1]][:2]))\n",
        "template_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2FdxNHtjgrL"
      },
      "source": [
        "target_values = []\n",
        "for part in parts_to_compare:\n",
        "  target_values.append(angle_length(target_kps[part[0]][:2], target_kps[part[1]][:2]))\n",
        "target_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUV7Ye7tDKJM"
      },
      "source": [
        "# with open('template.pkl', 'wb') as f:\n",
        "#   pickle.dump(template, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfRSl-DGDo6u"
      },
      "source": [
        "# with open('template.pkl', 'rb') as f:\n",
        "#   template = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfZjTUv8iro0"
      },
      "source": [
        "#### Matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00gXsGUoXNTR"
      },
      "source": [
        "def matching(template_kp, target_kp, angle_deviation=30, size_deviation=1):\n",
        "\n",
        "  '''Input:\n",
        "      1. template_kp - list of tuples (for the template image) containng angles\n",
        "      between particular body parts and x-axis as first elements and its sizes\n",
        "      (distances between corresponding points as second elements)\n",
        "      2. target_kp - same for the target image\n",
        "      3. angle_deviation - acceptable angle difference between corresponding\n",
        "      body parts in the images\n",
        "      4. size_deviation - acceptable proportions difference between the images\n",
        "    Output:\n",
        "      List of body parts which are deviated\n",
        "  '''\n",
        "\n",
        "  devs = []\n",
        "\n",
        "  # set an anchor size for proportions calculations - distance between shoulders\n",
        "  templ_anchor = template_kp[0][1]\n",
        "  targ_anchor = target_kp[0][1]\n",
        "\n",
        "  # for each body part that we calculated angle and size for\n",
        "  for i in range(len(template_kp)):\n",
        "\n",
        "    angles = (template_kp[i][0], target_kp[i][0])\n",
        "    diff_angle = max(angles) - min(angles)\n",
        "\n",
        "    templ_size = (template_kp[i][1],templ_anchor)\n",
        "    templ_size = abs(min(templ_size) / max(templ_size))\n",
        "\n",
        "    tar_size = (target_kp[i][1], targ_anchor)\n",
        "    tar_size = abs(min(tar_size) / max(tar_size))\n",
        "\n",
        "    if diff_angle > angle_deviation:\n",
        "      devs.append(i)\n",
        "      print(\"{0} has different angle\".format(i))\n",
        "\n",
        "    elif max(tar_size,templ_size) - min(tar_size,templ_size) > size_deviation:\n",
        "      devs.append(i)\n",
        "      print(\"{0} has different size\".format(i))\n",
        "\n",
        "  return devs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA43MoQeCMe9"
      },
      "source": [
        "deviations = matching(template_values, target_values)\n",
        "deviations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRizaxUNFc4T"
      },
      "source": [
        "#### Draw deviations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y5kFK4rFiXR"
      },
      "source": [
        "def draw_deviations(img, keypoints, pairs, deviations):\n",
        "\n",
        "  for i, pair in enumerate(pairs):\n",
        "\n",
        "    if i in deviations:\n",
        "      color = (0,0,255)\n",
        "    else:\n",
        "      color = (0,255,0)\n",
        "\n",
        "    cv.line(img, (keypoints[pair[0]][1], keypoints[pair[0]][0]), (keypoints[pair[1]][1], keypoints[pair[1]][0]), color=color, lineType=cv.LINE_AA, thickness=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuoZD2kblA7f"
      },
      "source": [
        "draw_deviations(target_show, target_kps, parts_to_compare, deviations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTk9BKLdDe1Q"
      },
      "source": [
        "cv2_imshow(target_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vCudk8Rfbnk"
      },
      "source": [
        "# cv.imwrite('devs.jpg', target_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVwtNDap-ZeZ"
      },
      "source": [
        "### Matching by finding the target pose in the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd1DFXL8NSly"
      },
      "source": [
        "#### Set a target pattern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zES77R0hLcxf"
      },
      "source": [
        "# Get a zero matrix with the shape of the template image\n",
        "template_pose = np.zeros_like(template_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onh_0-lVPB9p"
      },
      "source": [
        "# connect some of the points\n",
        "def join_point(img, kps):\n",
        "\n",
        "  body_parts = [(5,6),(5,7),(6,8),(7,9),(8,10),(11,12),(5,11),\n",
        "                      (6,12),(11,13),(12,14),(13,15),(14,16)]\n",
        "\n",
        "  for part in body_parts:\n",
        "    cv.line(img, (kps[part[0]][1], kps[part[0]][0]), (kps[part[1]][1], kps[part[1]][0]),\n",
        "            color=(255,255,255), lineType=cv.LINE_AA, thickness=3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b-o8Y7XZELY"
      },
      "source": [
        "# draw a skeleton of the template pose to the empty image\n",
        "join_point(template_pose, template_kps[:, :2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDDvcouZWpzp"
      },
      "source": [
        "cv2_imshow(template_pose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UNgzdSvAo8d"
      },
      "source": [
        "# set the new dimensions of the image to reduce the size\n",
        "buffer = 5 # size of the area around the pose\n",
        "top_left_y = min(template_kps[5:, 0]) - buffer\n",
        "top_left_x = min(template_kps[5:, 1]) - buffer\n",
        "buttom_right_y = max(template_kps[5:, 0]) + buffer\n",
        "buttom_right_x = max(template_kps[5:, 1]) + buffer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZaQ8TSJB53y"
      },
      "source": [
        "# crop the template pose with new dimensions\n",
        "template_pose = template_pose[top_left_y:buttom_right_y, top_left_x:buttom_right_x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fibtz40ZVN8"
      },
      "source": [
        "cv2_imshow(template_pose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqND9GDUAUOa"
      },
      "source": [
        "# save the template pattern\n",
        "# cv.imwrite('template_pose.jpg', template_pose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kKUM8XzZZNH"
      },
      "source": [
        "#### Find the pattern in the new image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVvaKyHjckDj"
      },
      "source": [
        "# Get a zero matrix with the shape of the target image\n",
        "target_pose = np.zeros_like(target_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92zRj8Cecsy6"
      },
      "source": [
        "# draw a skeleton of the target pose to the empty image\n",
        "join_point(target_pose, target_kps[:, :2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwD0dqcXBIRs"
      },
      "source": [
        "# set the new dimensions of the image to reduce the size\n",
        "buffer = 5 # size of the area around the pose\n",
        "top_left_y = min(target_kps[5:, 0]) - buffer\n",
        "top_left_x = min(target_kps[5:, 1]) - buffer\n",
        "buttom_right_y = max(target_kps[5:, 0]) + buffer\n",
        "buttom_right_x = max(target_kps[5:, 1]) + buffer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c35Zx7nRBQGw"
      },
      "source": [
        "target_pose = target_pose[top_left_y:buttom_right_y, top_left_x:buttom_right_x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It0obXgdFhyn"
      },
      "source": [
        "cv2_imshow(target_pose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z27IhjIe81l"
      },
      "source": [
        "template_pose = cv.cvtColor(template_pose, cv.COLOR_BGR2GRAY)\n",
        "target_pose = cv.cvtColor(target_pose, cv.COLOR_BGR2GRAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5cAbJ3w-5R4"
      },
      "source": [
        "# the greater the threshold the more exact the pose has to match\n",
        "threshold = 0.1\n",
        "\n",
        "w, h = target_pose.shape[::-1]\n",
        "res = cv.matchTemplate(target_pose,template_pose, cv.TM_CCOEFF_NORMED)\n",
        "score = res.max()\n",
        "\n",
        "print(\"score:\", score)\n",
        "\n",
        "if score >= threshold:\n",
        "  print(\"Match\")\n",
        "else:\n",
        "  print(\"Don't match\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mrIuPeYthAA"
      },
      "source": [
        "### Draw grid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mxHhuY51LKF"
      },
      "source": [
        "def draw_grid(img, grid_size=9, heatmap=None, part=1):\n",
        "\n",
        "    color = (0,255,255)\n",
        "\n",
        "    small_size = min(img.shape[0], img.shape[1])\n",
        "    cell_size = small_size // grid_size\n",
        "    res = int(small_size % grid_size)\n",
        "\n",
        "    x = res // 2\n",
        "    y = res // 2\n",
        "\n",
        "    while x < img.shape[1]:\n",
        "      cv.line(img, (x, 0), (x, img.shape[0]), color=color, lineType=cv.LINE_AA, thickness=1)\n",
        "      x += cell_size\n",
        "\n",
        "    while y < img.shape[0]:\n",
        "      cv.line(img, (0, y), (img.shape[1], y), color=color, lineType=cv.LINE_AA, thickness=1)\n",
        "      y += cell_size\n",
        "\n",
        "    center_x = res//2\n",
        "    center_y = res//2 + cell_size//2\n",
        "\n",
        "    cv.putText(image,str(round(heatmap[0,0,part],1)), (center_x,center_y), cv.FONT_HERSHEY_SIMPLEX, 0.3, color)\n",
        "\n",
        "    for row_idx, row in enumerate(heatmap[...,part]):\n",
        "\n",
        "      for col_idx, column in enumerate(row):\n",
        "        cv.putText(image,str(round(heatmap[col_idx,row_idx,part],1)), (center_x,center_y), cv.FONT_HERSHEY_SIMPLEX, 0.3, color)\n",
        "        center_y += cell_size\n",
        "\n",
        "      center_x += cell_size\n",
        "      center_y = res//2 + cell_size//2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BQbKpR20aTp"
      },
      "source": [
        "# image = cv.imread('image.jpg')\n",
        "# image = cv.resize(image, (257, 257))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuGHyDus1bRS"
      },
      "source": [
        "# draw_grid(image, 9, template_heatmaps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_gS5pZv0kEE"
      },
      "source": [
        "# cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_15jBuGczrA8"
      },
      "source": [
        "# cv.imwrite('image.jpg', image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}